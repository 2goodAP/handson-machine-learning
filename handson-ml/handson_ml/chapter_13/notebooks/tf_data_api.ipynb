{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d8d9cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:47:10.475993Z",
     "iopub.status.busy": "2024-02-14T10:47:10.474604Z",
     "iopub.status.idle": "2024-02-14T10:47:10.489913Z",
     "shell.execute_reply": "2024-02-14T10:47:10.488238Z",
     "shell.execute_reply.started": "2024-02-14T10:47:10.475919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/twogoodap/Coding_Playground/Machine_Learning/Hands_on_Machine_Learning/handson-ml/mlruns\n",
      "/home/twogoodap/Coding_Playground/Machine_Learning/Hands_on_Machine_Learning/handson-ml/handson_ml/chapter_13/dataset\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_DIR = Path().absolute().parent\n",
    "MLRUNS_DIR = ROOT_DIR.parents[1] / \"mlruns\"\n",
    "DATA_DIR = ROOT_DIR / \"dataset\"\n",
    "TFR_DIR = DATA_DIR / \"tfrecords\"\n",
    "PROTO_DIR = ROOT_DIR / \"protobufs\"\n",
    "\n",
    "if not TFR_DIR.is_dir():\n",
    "    TFR_DIR.mkdir(parents=True)\n",
    "if not PROTO_DIR.is_dir():\n",
    "    PROTO_DIR.mkdir(parents=True)\n",
    "\n",
    "print(f\"{MLRUNS_DIR}\\n{DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1925dd84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T06:23:21.745683Z",
     "iopub.status.busy": "2024-02-13T06:23:21.745569Z",
     "iopub.status.idle": "2024-02-13T06:23:22.436572Z",
     "shell.execute_reply": "2024-02-13T06:23:22.436144Z",
     "shell.execute_reply.started": "2024-02-13T06:23:21.745675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/twogoodap/Coding_Playground/Machine_Learning/Hands_on_Machine_Learning/handson-ml/handson_ml/chapter_13/mlruns/2', creation_time=1699089661167, experiment_id='2', last_update_time=1699089661167, lifecycle_stage='active', name='tf_data_api', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(f\"sqlite:///{MLRUNS_DIR}/mlflow.db\")\n",
    "mlflow.set_experiment(\"tf_data_api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f59e24b",
   "metadata": {},
   "source": [
    "## The `tensorflow.data` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622ec0e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T15:05:48.798785Z",
     "iopub.status.busy": "2024-02-10T15:05:48.798280Z",
     "iopub.status.idle": "2024-02-10T15:05:48.800885Z",
     "shell.execute_reply": "2024-02-10T15:05:48.800480Z",
     "shell.execute_reply.started": "2024-02-10T15:05:48.798769Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = data.Dataset.from_tensor_slices(tf.range(10))\n",
    "\n",
    "for t in ts:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb0bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = data.Dataset.range(10)\n",
    "\n",
    "for r in rs:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nested = {\"a\": ([1, 2, 3], [4, 5, 6]), \"b\": [7, 8, 9]}\n",
    "\n",
    "for x in data.Dataset.from_tensor_slices(X_nested):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc74d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nested = {\"a\": [[1, 2, 3], [4, 5, 6]], \"b\": [[7, 8, 9], [10, 11, 12]]}\n",
    "\n",
    "for x in data.Dataset.from_tensor_slices(X_nested):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5a6620",
   "metadata": {},
   "source": [
    "## Chaining Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf364ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5807d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.Dataset.range(10)\n",
    "\n",
    "for rb in dataset.repeat(5).batch(8):\n",
    "    print(rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for srb in dataset.shuffle(5, seed=42).repeat(5).batch(10):\n",
    "    print(srb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:  # No change\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9360a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for md in dataset.map(lambda x: 2 * x + 4, num_parallel_calls=data.AUTOTUNE):\n",
    "    print(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fd in (\n",
    "    dataset.map(lambda x: (4 * x + 5) // 2, num_parallel_calls=data.AUTOTUNE)\n",
    "    .repeat(5)\n",
    "    .batch(8)\n",
    "    .filter(lambda x: tf.reduce_sum(x) > 80)\n",
    "):\n",
    "    print(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d00a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in dataset.repeat().batch(7).take(5):  # 5 out of inf\n",
    "    print(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3257c2f",
   "metadata": {},
   "source": [
    "## Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import data\n",
    "\n",
    "dataset = data.Dataset.range(10)\n",
    "\n",
    "for srd in dataset.shuffle(buffer_size=10, seed=42).repeat(10).batch(16):\n",
    "    print(srd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38789d18",
   "metadata": {},
   "source": [
    "## Preprocessing using `tf.data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c2e694",
   "metadata": {},
   "source": [
    "### Creating the split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as cd\n",
    "import dask_cudf as dcd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "dcd.from_cudf(\n",
    "    cd.from_dataframe(\n",
    "        fetch_california_housing(as_frame=True)[\"frame\"], allow_copy=True\n",
    "    ),\n",
    "    npartitions=5,\n",
    ").to_csv(str(DATA_DIR / \"california_housing\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a764c0",
   "metadata": {},
   "source": [
    "### Reading csv using `tf.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37edc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import data, io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99882531",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUTS = 8\n",
    "\n",
    "\n",
    "def parse_csv_line(line: str) -> tuple[tf.Tensor, tf.Tensor]:\n",
    "    fields = io.decode_csv(\n",
    "        line, record_defaults=[0.0] * N_INPUTS + [tf.constant([], dtype=tf.float32)]\n",
    "    )\n",
    "\n",
    "    return tf.stack(fields[:-1]), tf.stack(fields[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00609e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_READERS, N_THREADS, SEED = 5, 5, 42\n",
    "\n",
    "dataset = (\n",
    "    (\n",
    "        data.Dataset.list_files(\n",
    "            str(DATA_DIR / \"california_housing\" / \"*.part\"), seed=SEED\n",
    "        )\n",
    "        .interleave(\n",
    "            lambda f: data.TextLineDataset(f).skip(1),\n",
    "            cycle_length=N_READERS,\n",
    "            num_parallel_calls=N_THREADS,\n",
    "        )\n",
    "        .map(parse_csv_line, num_parallel_calls=N_THREADS)\n",
    "    )\n",
    "    .shuffle(buffer_size=10_000)\n",
    "    .batch(32)\n",
    "    .prefetch(data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset.take(1):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98ad70",
   "metadata": {},
   "source": [
    "## TfRecord Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9332d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "from tensorflow.io import TFRecordOptions, TFRecordWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with TFRecordWriter(str(TFR_DIR / \"first.tfrecord\")) as f:\n",
    "    f.write(b\"First Record: 01\")\n",
    "    f.write(b\"First Record: 02\")\n",
    "    f.write(b\"First Record: 03\")\n",
    "\n",
    "with TFRecordWriter(str(TFR_DIR / \"second.tfrecord\")) as f:\n",
    "    f.write(b\"Second Record: 01\")\n",
    "    f.write(b\"Second Record: 02\")\n",
    "    f.write(b\"Second Record: 03\")\n",
    "\n",
    "with TFRecordWriter(str(TFR_DIR / \"third.tfrecord\")) as f:\n",
    "    f.write(b\"Third Record: 01\")\n",
    "    f.write(b\"Third Record: 02\")\n",
    "    f.write(b\"Third Record: 03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "rec_ds = data.TFRecordDataset(\n",
    "    glob.glob(str(TFR_DIR / \"*.tfrecord\")), num_parallel_reads=3\n",
    ")\n",
    "\n",
    "for r in rec_ds:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f25107c",
   "metadata": {},
   "source": [
    "## Protocol Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34472cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "from tensorflow.io import TFRecordOptions, TFRecordWriter"
   ]
  },
  {
   "cell_type": "raw",
   "id": "135a66c2",
   "metadata": {},
   "source": [
    "%%writefile protobufs/person.proto\n",
    "syntax = \"proto3\";\n",
    "message Person {\n",
    "    string name = 1;\n",
    "    int32 id = 2;\n",
    "    repeated string emails = 3;\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79241043",
   "metadata": {},
   "source": [
    "!protoc --python_out=. --include_imports \\\n",
    "    --descriptor_set_out=protobufs/person.desc \\\n",
    "    protobufs/person.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410554dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from protobufs.person_pb2 import Person\n",
    "\n",
    "person = Person(name=\"Al\", id=22, emails=[\"al@alexandro.com\"])\n",
    "person.emails.append(\"john@richard.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32005211",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(person)\n",
    "print(person.name)\n",
    "print(person.id)\n",
    "person.name = \"Alexandro\"\n",
    "print(person.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b62879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((serialized := person.SerializeToString()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bada21",
   "metadata": {},
   "outputs": [],
   "source": [
    "person2 = Person()\n",
    "person2.ParseFromString(serialized) == len(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "person2 == person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3299ce",
   "metadata": {},
   "source": [
    "### Decoding Custom Protobuf using Tensorflow Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.decode_proto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a06aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    person_tf := tf.io.decode_proto(\n",
    "        bytes=serialized,\n",
    "        message_type=\"Person\",\n",
    "        field_names=[\"name\", \"id\", \"emails\"],\n",
    "        output_types=[tf.string, tf.int32, tf.string],\n",
    "        descriptor_source=str(PROTO_DIR / \"person.desc\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7115cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_tf.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea95af",
   "metadata": {},
   "source": [
    "### TensorFlow Protobufs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbd590d",
   "metadata": {},
   "source": [
    "```proto\n",
    "syntax = \"proto3\";\n",
    "\n",
    "message BytesList { repeated bytes value = 1; }\n",
    "message FloatList { repeated float value = 1 [packed = true]; }\n",
    "message Int64List { repeated int64 value = 1 [packed = true]; }\n",
    "message Feature {\n",
    "    oneof kind {\n",
    "        BytesList bytes_list = 1;\n",
    "        FloatList float_list = 2;\n",
    "        Int64List int64_list = 3;\n",
    "    }\n",
    "};\n",
    "message Features { map<string, Feature> feature = 1; };\n",
    "message Example { Features features = 1; };\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, Example, Feature, Features, Int64List\n",
    "\n",
    "(\n",
    "    person_example := Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"name\": Feature(bytes_list=BytesList(value=[b\"Alejandro\"])),\n",
    "                \"id\": Feature(int64_list=Int64List(value=[1])),\n",
    "                \"emails\": Feature(\n",
    "                    bytes_list=BytesList(\n",
    "                        value=[b\"al@alejandro.com\", b\"bal@balkrishna.org\"]\n",
    "                    )\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095fb753",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr_options = {\"compression_type\": \"GZIP\"}\n",
    "\n",
    "with TFRecordWriter(\n",
    "    str(DATA_DIR / \"tfrecords\" / \"person_example.tfrecord\"),\n",
    "    options=TFRecordOptions(**tfr_options),\n",
    ") as f:\n",
    "    f.write(person_example.SerializeToString())\n",
    "\n",
    "del person_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58af13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ea651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.io import FixedLenFeature, VarLenFeature\n",
    "\n",
    "person_ds = data.TFRecordDataset(\n",
    "    str(DATA_DIR / \"tfrecords\" / \"person_example.tfrecord.gz\"), **tfr_options\n",
    ").map(\n",
    "    lambda ex: tf.io.parse_example(\n",
    "        ex,\n",
    "        features={\n",
    "            \"name\": VarLenFeature(dtype=tf.string),\n",
    "            \"id\": FixedLenFeature(shape=(), dtype=tf.int64),\n",
    "            \"emails\": VarLenFeature(dtype=tf.string),\n",
    "        },\n",
    "    ),\n",
    "    num_parallel_calls=data.AUTOTUNE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in person_ds:\n",
    "    print(tf.sparse.to_dense(p[\"name\"]))\n",
    "    print(p[\"id\"])\n",
    "    print(p[\"emails\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4b98f",
   "metadata": {},
   "source": [
    "### Serializing Images and Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_sample_images\n",
    "\n",
    "img = load_sample_images()[\"images\"][0]\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only necessary if image is not already a .jpeg\n",
    "tf.io.encode_jpeg(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede51f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_example = Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"image\": Feature(\n",
    "                bytes_list=BytesList(value=[tf.io.encode_jpeg(img).numpy()])\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b38ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with TFRecordWriter(\n",
    "    str(TFR_DIR / \"image_example.tfrecord.gz\"), options=TFRecordOptions(**tfr_options)\n",
    ") as f:\n",
    "    f.write(img_example.SerializeToString())\n",
    "\n",
    "del img_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea288914",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ds = data.TFRecordDataset(\n",
    "    str(TFR_DIR / \"image_example.tfrecord.gz\"), **tfr_options\n",
    ").map(\n",
    "    lambda ex: tf.io.decode_jpeg(\n",
    "        tf.io.parse_single_example(\n",
    "            ex, features={\"image\": VarLenFeature(dtype=tf.string)}\n",
    "        )[\"image\"].values[0]\n",
    "    ),\n",
    "    num_parallel_calls=data.AUTOTUNE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in img_ds:\n",
    "    plt.imshow(i)\n",
    "    plt.title(\"Decoded Image\")\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c97fb",
   "metadata": {},
   "source": [
    "## `SequenceExample` Protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1b8ec",
   "metadata": {},
   "source": [
    "```proto\n",
    "syntax = \"proto3\";\n",
    "\n",
    "message FeatureList { repeated Feature feature = 1; };\n",
    "message FeatureLists { map<string, FeatureList> feature_list = 1; };\n",
    "message SequenceExample {\n",
    "    Features context = 1;\n",
    "    FeatureLists feature_lists = 2;\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8620c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "from tensorflow.train import FeatureList, FeatureLists, SequenceExample\n",
    "\n",
    "context = Features(\n",
    "    feature={\n",
    "        \"author_id\": Feature(int64_list=Int64List(value=[123])),\n",
    "        \"title\": Feature(bytes_list=BytesList(value=[b\"A\", b\"Desert\", b\"Place\", b\".\"])),\n",
    "        \"pub_date\": Feature(int64_list=Int64List(value=[1623, 12, 25])),\n",
    "    }\n",
    ")\n",
    "\n",
    "content = [\n",
    "    [\"When\", \"shall\", \"we\", \"three\", \"meet\", \"again\", \"?\"],\n",
    "    [\"In\", \"thunder\", \",\", \"lightning\", \",\", \"or\", \"in\", \"rain\", \"?\"],\n",
    "]\n",
    "comments = [\n",
    "    [\"When\", \"the\", \"hurlyburly\", \"'s\", \"done\", \".\"],\n",
    "    [\"When\", \"the\", \"battle\", \"'s\", \"lost\", \"and\", \"won\", \".\"],\n",
    "]\n",
    "\n",
    "\n",
    "def words_to_feature(words: Iterable[str]) -> Feature:\n",
    "    return Feature(\n",
    "        bytes_list=BytesList(value=[bytes(word, encoding=\"utf8\") for word in words])\n",
    "    )\n",
    "\n",
    "\n",
    "(\n",
    "    seq_example := SequenceExample(\n",
    "        context=context,\n",
    "        feature_lists=FeatureLists(\n",
    "            feature_list={\n",
    "                \"content\": FeatureList(\n",
    "                    feature=[words_to_feature(words) for words in content]\n",
    "                ),\n",
    "                \"comments\": FeatureList(\n",
    "                    feature=[words_to_feature(words) for words in comments]\n",
    "                ),\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "with TFRecordWriter(\n",
    "    str(TFR_DIR / \"sequence_example.tfrecord.gz\"),\n",
    "    options=TFRecordOptions(**tfr_options),\n",
    ") as f:\n",
    "    f.write(seq_example.SerializeToString())\n",
    "\n",
    "del seq_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9881b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ds = data.TFRecordDataset(\n",
    "    str(TFR_DIR / \"sequence_example.tfrecord.gz\"), **tfr_options\n",
    ").map(\n",
    "    lambda ex: tf.io.parse_single_sequence_example(\n",
    "        ex,\n",
    "        context_features={\n",
    "            \"author_id\": FixedLenFeature(shape=(), dtype=tf.int64),\n",
    "            \"title\": VarLenFeature(dtype=tf.string),\n",
    "            \"pub_date\": FixedLenFeature(shape=(3,), dtype=tf.int64),\n",
    "        },\n",
    "        sequence_features={\n",
    "            \"content\": VarLenFeature(dtype=tf.string),\n",
    "            \"comments\": VarLenFeature(dtype=tf.string),\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parsed_context, s in seq_ds:\n",
    "    parsed_sequences = {k: tf.RaggedTensor.from_sparse(v) for k, v in s.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1cb76b",
   "metadata": {},
   "source": [
    "## Keras Preprocessing Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc83231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T06:23:46.989194Z",
     "iopub.status.busy": "2024-02-13T06:23:46.988918Z",
     "iopub.status.idle": "2024-02-13T06:23:46.994834Z",
     "shell.execute_reply": "2024-02-13T06:23:46.993481Z",
     "shell.execute_reply.started": "2024-02-13T06:23:46.989180Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import data, keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f64947c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T06:23:49.934330Z",
     "iopub.status.busy": "2024-02-13T06:23:49.933705Z",
     "iopub.status.idle": "2024-02-13T06:23:50.225687Z",
     "shell.execute_reply": "2024-02-13T06:23:50.225251Z",
     "shell.execute_reply.started": "2024-02-13T06:23:49.934307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "del housing, X_train_full, y_train_full\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224aeb45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T06:34:01.472544Z",
     "iopub.status.busy": "2024-02-13T06:34:01.471987Z",
     "iopub.status.idle": "2024-02-13T06:34:01.478157Z",
     "shell.execute_reply": "2024-02-13T06:34:01.477220Z",
     "shell.execute_reply.started": "2024-02-13T06:34:01.472529Z"
    }
   },
   "outputs": [],
   "source": [
    "norm = layers.Normalization()\n",
    "model = keras.Sequential([norm, layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37187c76-54f4-439a-aa36-f0a10361cb77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T07:38:15.423386Z",
     "iopub.status.busy": "2024-02-13T07:38:15.422769Z",
     "iopub.status.idle": "2024-02-13T07:38:15.433464Z",
     "shell.execute_reply": "2024-02-13T07:38:15.431649Z",
     "shell.execute_reply.started": "2024-02-13T07:38:15.423330Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_TOKENS = 5\n",
    "inp = tf.constant([[1], [0], [2], [0], [3], [2], [4]])\n",
    "minp = tf.constant([[1, 2], [0, 1], [2, 3], [0, 0], [3, 4], [2, 1], [4, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60119297-3183-414c-b0e2-24045fc8f001",
   "metadata": {},
   "source": [
    "### `CategoryEncoding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c823369-9fcb-4f07-8d07-8a61b9fbd97e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T07:38:16.946383Z",
     "iopub.status.busy": "2024-02-13T07:38:16.945776Z",
     "iopub.status.idle": "2024-02-13T07:38:16.965058Z",
     "shell.execute_reply": "2024-02-13T07:38:16.963687Z",
     "shell.execute_reply.started": "2024-02-13T07:38:16.946329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 10), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_enc = layers.CategoryEncoding(num_tokens=2 * NUM_TOKENS, output_mode=\"multi_hot\")\n",
    "cat_enc(minp + [0, NUM_TOKENS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a92be20a-5168-4380-b718-a7f595e164e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T07:39:24.803760Z",
     "iopub.status.busy": "2024-02-13T07:39:24.802922Z",
     "iopub.status.idle": "2024-02-13T07:39:24.833789Z",
     "shell.execute_reply": "2024-02-13T07:39:24.832593Z",
     "shell.execute_reply.started": "2024-02-13T07:39:24.803701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minp.T:\n",
      "[[1 0 2 0 3 2 4]\n",
      " [2 1 3 0 4 1 0]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 10), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"minp.T:\\n{tf.transpose(minp)}\\n\")\n",
    "oh_enc = layers.CategoryEncoding(num_tokens=NUM_TOKENS, output_mode=\"one_hot\")\n",
    "layers.Concatenate()([oh_enc(m) for m in tf.transpose(minp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98be140c-f70a-49f5-81e2-d09654a4707f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-13T07:42:16.269995Z",
     "iopub.status.busy": "2024-02-13T07:42:16.269233Z",
     "iopub.status.idle": "2024-02-13T07:42:16.296344Z",
     "shell.execute_reply": "2024-02-13T07:42:16.294796Z",
     "shell.execute_reply.started": "2024-02-13T07:42:16.269928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 10), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Flatten()(tf.one_hot(minp, depth=NUM_TOKENS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
