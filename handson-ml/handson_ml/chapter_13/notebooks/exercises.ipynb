{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aece43b-1bc8-4ece-9742-233886d52981",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4aa2e9-8b82-4f54-8555-c46365db88ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T11:09:12.741449Z",
     "iopub.status.busy": "2024-02-19T11:09:12.741158Z",
     "iopub.status.idle": "2024-02-19T11:09:12.744699Z",
     "shell.execute_reply": "2024-02-19T11:09:12.744296Z",
     "shell.execute_reply.started": "2024-02-19T11:09:12.741435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/twogoodap/Coding_Playground/Machine_Learning/Hands_on_Machine_Learning/handson-ml/mlruns\n",
      "/home/twogoodap/Coding_Playground/Machine_Learning/Hands_on_Machine_Learning/handson-ml/handson_ml/chapter_13/dataset\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import data, keras\n",
    "\n",
    "ROOT_DIR = Path().absolute().parent\n",
    "MLRUNS_DIR = ROOT_DIR.parents[1] / \"mlruns\"\n",
    "DATA_DIR = ROOT_DIR / \"dataset\"\n",
    "PROTO_DIR = ROOT_DIR / \"protobufs\"\n",
    "TFR_DIR = DATA_DIR / \"tfrecords\"\n",
    "IMDB_DIR = DATA_DIR / \"large_movie_review\"\n",
    "\n",
    "if not TFR_DIR.is_dir():\n",
    "    TFR_DIR.mkdir(parents=True)\n",
    "if not PROTO_DIR.is_dir():\n",
    "    PROTO_DIR.mkdir(parents=True)\n",
    "\n",
    "print(f\"{MLRUNS_DIR}\\n{DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96619b4-58cf-48c3-8f89-9360039455c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T11:09:13.609333Z",
     "iopub.status.busy": "2024-02-19T11:09:13.608976Z",
     "iopub.status.idle": "2024-02-19T11:09:13.973094Z",
     "shell.execute_reply": "2024-02-19T11:09:13.972736Z",
     "shell.execute_reply.started": "2024-02-19T11:09:13.609304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/twogoodap/Coding_Playground/Machine_Learning/Hands_on_Machine_Learning/handson-ml/handson_ml/chapter_13/mlruns/2', creation_time=1699089661167, experiment_id='2', last_update_time=1699089661167, lifecycle_stage='active', name='tf_data_api', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(f\"sqlite:///{MLRUNS_DIR}/mlflow.db\")\n",
    "mlflow.set_experiment(\"tf_data_api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c368e5-b864-4a1c-b119-cec8d8de262e",
   "metadata": {},
   "source": [
    "## 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef663e6f-b917-4741-91da-d57074429f25",
   "metadata": {},
   "source": [
    "```proto\n",
    "syntax = \"proto3\";\n",
    "\n",
    "message BytesList { repeated bytes value = 1; }\n",
    "message FloatList { repeated float value = 1 [packed = true]; }\n",
    "message Int64List { repeated int64 value = 1 [packed = true]; }\n",
    "message Feature {\n",
    "    oneof kind {\n",
    "        BytesList bytes_list = 1;\n",
    "        FloatList float_list = 2;\n",
    "        Int64List int64_list = 3;\n",
    "    }\n",
    "};\n",
    "message Features { map<string, Feature> feature = 1; };\n",
    "message Example { Features features = 1; };\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "80e57c12-d1e2-4934-99c2-86f3291daf23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T11:38:07.772560Z",
     "iopub.status.busy": "2024-02-17T11:38:07.771880Z",
     "iopub.status.idle": "2024-02-17T11:38:07.792784Z",
     "shell.execute_reply": "2024-02-17T11:38:07.790849Z",
     "shell.execute_reply.started": "2024-02-17T11:38:07.772497Z"
    }
   },
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.train import BytesList, Example, Feature, Features, Int64List\n",
    "\n",
    "\n",
    "def fashion_mnist_to_tfrecord(\n",
    "    dataset: data.Dataset,\n",
    "    name: str,\n",
    "    record_dir: Path = TFR_DIR / \"fashion_mnist\",\n",
    "    n_shards: int = 10,\n",
    "    seed: int = 42,\n",
    ") -> list[str]:\n",
    "    def __fashion_mnist_example(image: np.ndarray | tf.Tensor, label: str) -> Example:\n",
    "        return Example(\n",
    "            features=Features(\n",
    "                feature={\n",
    "                    \"image\": Feature(\n",
    "                        bytes_list=BytesList(\n",
    "                            value=[tf.io.serialize_tensor(image).numpy()]\n",
    "                        )\n",
    "                    ),\n",
    "                    \"label\": Feature(int64_list=Int64List(value=[int(label)])),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "    (record_dir / name).mkdir(parents=True, exist_ok=True)\n",
    "    paths = [\n",
    "        str(record_dir / name / f\"{shard:03}.tfrecord\") for shard in range(n_shards)\n",
    "    ]\n",
    "\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path)) for path in paths]\n",
    "\n",
    "        for i, (img, lbl) in dataset.enumerate():\n",
    "            writers[i % n_shards].write(\n",
    "                __fashion_mnist_example(img, lbl).SerializeToString()\n",
    "            )\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "a1f18ea5-dfe8-42b6-8b13-9eece0510673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T11:38:10.754942Z",
     "iopub.status.busy": "2024-02-17T11:38:10.754776Z",
     "iopub.status.idle": "2024-02-17T11:38:15.699001Z",
     "shell.execute_reply": "2024-02-17T11:38:15.698310Z",
     "shell.execute_reply.started": "2024-02-17T11:38:10.754928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96135"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BUFFER_SIZE = 10_000\n",
    "SEED = 42\n",
    "\n",
    "images, targets = (\n",
    "    (fmnist := fetch_openml(name=\"Fashion-MNIST\", as_frame=False, parser=\"auto\")).data,\n",
    "    fmnist.target,\n",
    ")\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    images.reshape(-1, 28, 28).astype(\"uint8\"),\n",
    "    targets,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=targets,\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=SEED, stratify=y_train_full\n",
    ")\n",
    "del X_train_full, y_train_full\n",
    "\n",
    "train_set, val_set, test_set = (\n",
    "    data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(\n",
    "        buffer_size=BUFFER_SIZE\n",
    "    ),\n",
    "    data.Dataset.from_tensor_slices((X_val, y_val)),\n",
    "    data.Dataset.from_tensor_slices((X_test, y_test)),\n",
    ")\n",
    "\n",
    "del X_train, y_train, X_val, y_val, X_test, y_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "9da42e90-8cca-446d-8619-57a701fe363a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T11:38:15.699965Z",
     "iopub.status.busy": "2024-02-17T11:38:15.699840Z",
     "iopub.status.idle": "2024-02-17T11:38:32.143418Z",
     "shell.execute_reply": "2024-02-17T11:38:32.142841Z",
     "shell.execute_reply.started": "2024-02-17T11:38:15.699953Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 17:23:15.705397: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-02-17 17:23:25.743780: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-02-17 17:23:28.697177: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4133"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = fashion_mnist_to_tfrecord(train_set, name=\"train\")\n",
    "val_paths = fashion_mnist_to_tfrecord(val_set, name=\"validation\")\n",
    "test_paths = fashion_mnist_to_tfrecord(test_set, name=\"test\")\n",
    "\n",
    "del train_set, val_set, test_set\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "de5bdce8-5163-4bde-a879-884bb91e1080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T11:38:32.148950Z",
     "iopub.status.busy": "2024-02-17T11:38:32.148832Z",
     "iopub.status.idle": "2024-02-17T11:38:32.616706Z",
     "shell.execute_reply": "2024-02-17T11:38:32.616369Z",
     "shell.execute_reply.started": "2024-02-17T11:38:32.148937Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 17:23:32.581657: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5261512097476009598\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "from tensorflow.io import FixedLenFeature\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "BUFFER_SIZE = 10_000\n",
    "N_THREADS = data.AUTOTUNE\n",
    "\n",
    "\n",
    "def create_tfrecord_dataset(\n",
    "    record_paths: list[str],\n",
    "    batch_size: int = 128,\n",
    "    n_threads: int | None = N_THREADS,\n",
    "    cache: bool = False,\n",
    "    shuffle_buf_size: int | None = None,\n",
    "    seed: int = 42,\n",
    ") -> data.TFRecordDataset:\n",
    "    def __parse_fashion_mnist_tfrecord(record: bytes) -> tuple[tf.Tensor, tf.Tensor]:\n",
    "        parsed = tf.io.parse_example(\n",
    "            record,\n",
    "            features={\n",
    "                \"image\": FixedLenFeature(shape=(), dtype=tf.string, default_value=\"\"),\n",
    "                \"label\": FixedLenFeature(shape=(), dtype=tf.int64),\n",
    "            },\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            tf.ensure_shape(\n",
    "                tf.io.parse_tensor(parsed[\"image\"], out_type=tf.uint8), shape=(28, 28)\n",
    "            ),\n",
    "            tf.cast(parsed[\"label\"], dtype=tf.uint8),\n",
    "        )\n",
    "\n",
    "    dataset = data.TFRecordDataset(record_paths, num_parallel_reads=n_threads).map(\n",
    "        __parse_fashion_mnist_tfrecord, num_parallel_calls=n_threads\n",
    "    )\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buf_size is not None:\n",
    "        dataset = dataset.shuffle(\n",
    "            buffer_size=shuffle_buf_size, seed=SEED, reshuffle_each_iteration=True\n",
    "        )\n",
    "\n",
    "    return dataset.batch(\n",
    "        batch_size, drop_remainder=True, num_parallel_calls=n_threads\n",
    "    ).prefetch(n_threads)\n",
    "\n",
    "\n",
    "train_set = create_tfrecord_dataset(\n",
    "    glob(str(TFR_DIR / \"fashion_mnist\" / \"train\" / \"*.tfrecord\")),\n",
    "    shuffle_buf_size=BUFFER_SIZE,\n",
    ")\n",
    "\n",
    "(norm := layers.Normalization(input_shape=train_set.element_spec[0].shape[1:])).adapt(\n",
    "    train_set.map(lambda X, y: X, num_parallel_calls=N_THREADS)\n",
    ")\n",
    "\n",
    "train_set = train_set.map(lambda X, y: (norm(X), y), num_parallel_calls=N_THREADS)\n",
    "\n",
    "val_set = create_tfrecord_dataset(\n",
    "    glob(str(TFR_DIR / \"fashion_mnist\" / \"validation\" / \"*.tfrecord\")),\n",
    "    cache=True,\n",
    ").map(lambda X, y: (norm(X), y), num_parallel_calls=N_THREADS)\n",
    "\n",
    "test_set = create_tfrecord_dataset(\n",
    "    glob(str(TFR_DIR / \"fashion_mnist\" / \"test\" / \"*.tfrecord\")),\n",
    "    cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "7b7c6ce1-b454-43fd-8a40-42bff4bcbe39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T11:38:32.617091Z",
     "iopub.status.busy": "2024-02-17T11:38:32.617013Z",
     "iopub.status.idle": "2024-02-17T11:38:32.802878Z",
     "shell.execute_reply": "2024-02-17T11:38:32.802513Z",
     "shell.execute_reply.started": "2024-02-17T11:38:32.617084Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "(<tf.Tensor: shape=(128, 28, 28), dtype=float32, numpy=\n",
      "array([[[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ]],\n",
      "\n",
      "       [[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ]],\n",
      "\n",
      "       [[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ]],\n",
      "\n",
      "       [[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ]],\n",
      "\n",
      "       [[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 ,  0.7591989 ,  4.9662666 , ...,  2.939328  ,\n",
      "          2.4505823 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466,  5.588145  , ...,  3.2137463 ,\n",
      "          1.4784681 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466,  0.659187  , ...,  0.9461835 ,\n",
      "         -0.3833782 , -0.2408609 ]]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=uint8, numpy=\n",
      "array([3, 1, 9, 8, 6, 9, 3, 4, 8, 0, 1, 5, 1, 6, 0, 5, 8, 9, 5, 6, 2, 3,\n",
      "       7, 2, 2, 4, 7, 3, 6, 2, 3, 0, 5, 8, 0, 5, 1, 9, 1, 2, 1, 1, 6, 8,\n",
      "       8, 3, 5, 3, 4, 1, 5, 9, 6, 0, 1, 5, 1, 7, 5, 2, 8, 0, 6, 4, 7, 7,\n",
      "       8, 8, 8, 0, 3, 2, 5, 2, 9, 7, 0, 8, 7, 3, 5, 6, 5, 6, 7, 2, 8, 7,\n",
      "       1, 1, 8, 0, 9, 9, 9, 5, 5, 0, 6, 6, 7, 3, 8, 3, 4, 9, 5, 7, 6, 5,\n",
      "       5, 9, 3, 7, 4, 6, 4, 4, 0, 9, 5, 4, 4, 4, 5, 3, 9, 8], dtype=uint8)>)\n",
      "\n",
      "Val:\n",
      "(<tf.Tensor: shape=(128, 28, 28), dtype=float32, numpy=\n",
      "array([[[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ]],\n",
      "\n",
      "       [[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ]],\n",
      "\n",
      "       [[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ]],\n",
      "\n",
      "       [[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ]],\n",
      "\n",
      "       [[-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        ...,\n",
      "        [-0.1670863 , -0.23698466,  0.06034175, ..., -0.46923783,\n",
      "         -0.30099565, -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ],\n",
      "        [-0.1670863 , -0.23698466, -0.2851459 , ..., -0.46923783,\n",
      "         -0.3833782 , -0.2408609 ]]], dtype=float32)>, <tf.Tensor: shape=(128,), dtype=uint8, numpy=\n",
      "array([7, 5, 7, 0, 9, 3, 8, 0, 6, 1, 2, 2, 8, 3, 2, 6, 8, 9, 8, 6, 7, 7,\n",
      "       4, 3, 1, 9, 0, 0, 0, 9, 3, 4, 5, 8, 0, 1, 4, 5, 1, 3, 9, 6, 1, 1,\n",
      "       2, 1, 3, 7, 5, 8, 4, 8, 9, 7, 5, 0, 9, 3, 3, 9, 8, 4, 5, 6, 1, 2,\n",
      "       4, 1, 4, 6, 1, 2, 4, 3, 7, 4, 9, 2, 4, 6, 7, 6, 1, 1, 4, 3, 8, 3,\n",
      "       6, 4, 9, 5, 5, 1, 1, 1, 6, 0, 6, 2, 0, 7, 7, 2, 3, 7, 8, 8, 9, 7,\n",
      "       1, 8, 1, 0, 0, 2, 1, 5, 7, 0, 7, 5, 2, 6, 1, 6, 5, 8], dtype=uint8)>)\n",
      "\n",
      "Test:\n",
      "(<tf.Tensor: shape=(128, 28, 28), dtype=uint8, numpy=\n",
      "array([[[  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   1,   0,   0],\n",
      "        [  0,   0,   1, ...,   2,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   5, ..., 221,   1,   0],\n",
      "        [  0,   0,  52, ..., 202,  68,   0],\n",
      "        [  0,   0,  34, ...,  71,  48,   0]],\n",
      "\n",
      "       [[  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   1,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   2,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0],\n",
      "        [  0,   0,   0, ...,   0,   0,   0]]], dtype=uint8)>, <tf.Tensor: shape=(128,), dtype=uint8, numpy=\n",
      "array([6, 3, 4, 8, 4, 7, 4, 3, 0, 1, 7, 7, 4, 7, 6, 2, 4, 1, 2, 1, 5, 8,\n",
      "       4, 3, 1, 2, 8, 4, 8, 8, 5, 9, 4, 4, 8, 5, 4, 9, 7, 0, 8, 1, 1, 6,\n",
      "       3, 2, 0, 1, 6, 6, 6, 4, 2, 8, 7, 0, 1, 6, 3, 6, 6, 7, 2, 7, 7, 1,\n",
      "       8, 6, 7, 7, 3, 5, 6, 4, 5, 3, 0, 4, 2, 6, 5, 6, 1, 8, 5, 6, 1, 8,\n",
      "       6, 2, 3, 7, 6, 0, 6, 4, 2, 8, 8, 5, 5, 2, 6, 8, 4, 5, 5, 8, 2, 6,\n",
      "       7, 6, 8, 0, 6, 9, 5, 3, 1, 6, 7, 1, 8, 1, 9, 8, 0, 4], dtype=uint8)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 17:23:32.782728: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-02-17 17:23:32.799287: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for trs in train_set.take(1):\n",
    "    print(\"Train:\")\n",
    "    print(trs)\n",
    "\n",
    "for vs in val_set.take(1):\n",
    "    print(\"\\nVal:\")\n",
    "    print(vs)\n",
    "\n",
    "for tes in test_set.take(1):\n",
    "    print(\"\\nTest:\")\n",
    "    print(tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "219ba224-8168-4a4b-ad65-03cb58763ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T11:38:32.803539Z",
     "iopub.status.busy": "2024-02-17T11:38:32.803417Z",
     "iopub.status.idle": "2024-02-17T11:38:32.867988Z",
     "shell.execute_reply": "2024-02-17T11:38:32.867307Z",
     "shell.execute_reply.started": "2024-02-17T11:38:32.803527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_13 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " batch_normalization_59 (Ba  (None, 100)               400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " batch_normalization_60 (Ba  (None, 50)                200       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " batch_normalization_61 (Ba  (None, 50)                200       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87410 (341.45 KB)\n",
      "Trainable params: 87010 (339.88 KB)\n",
      "Non-trainable params: 400 (1.56 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Flatten(input_shape=train_set.element_spec[0].shape[1:]),\n",
    "        layers.Dense(100, activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(50, activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(50, activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=\"nadam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    jit_compile=True,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9c51dbb7-7f10-4145-ae59-b94c57afe519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T11:38:32.868770Z",
     "iopub.status.busy": "2024-02-17T11:38:32.868647Z",
     "iopub.status.idle": "2024-02-17T11:39:04.976141Z",
     "shell.execute_reply": "2024-02-17T11:39:04.975411Z",
     "shell.execute_reply.started": "2024-02-17T11:38:32.868757Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/17 17:23:32 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n",
      "2024/02/17 17:23:32 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b6a8ddb40ab24d31a1d6cf80cc25e6c9', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "      1/Unknown - 2s 2s/step - loss: 2.8764 - accuracy: 0.1172WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0055s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0055s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 3s 3ms/step - loss: 0.5428 - accuracy: 0.8147 - val_loss: 0.4280 - val_accuracy: 0.8451\n",
      "Epoch 2/1000\n",
      " 42/328 [==>...........................] - ETA: 0s - loss: 0.3706 - accuracy: 0.8664 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 17:23:36.872517: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 11953096714435921924\n",
      "2024-02-17 17:23:36.872606: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 37581899012378094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 1s 3ms/step - loss: 0.3637 - accuracy: 0.8688 - val_loss: 0.3688 - val_accuracy: 0.8640\n",
      "Epoch 3/1000\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.3191 - accuracy: 0.8833 - val_loss: 0.3540 - val_accuracy: 0.8711\n",
      "Epoch 4/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.2906 - accuracy: 0.8928 - val_loss: 0.3562 - val_accuracy: 0.8701\n",
      "Epoch 5/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.2716 - accuracy: 0.8989 - val_loss: 0.3422 - val_accuracy: 0.8734\n",
      "Epoch 6/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.2522 - accuracy: 0.9071 - val_loss: 0.3403 - val_accuracy: 0.8802\n",
      "Epoch 7/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.2363 - accuracy: 0.9119 - val_loss: 0.3375 - val_accuracy: 0.8847\n",
      "Epoch 8/1000\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2229 - accuracy: 0.9164 - val_loss: 0.3389 - val_accuracy: 0.8840\n",
      "Epoch 9/1000\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.2151 - accuracy: 0.9192 - val_loss: 0.3517 - val_accuracy: 0.8808\n",
      "Epoch 10/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.2000 - accuracy: 0.9257 - val_loss: 0.3392 - val_accuracy: 0.8833\n",
      "Epoch 11/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.1899 - accuracy: 0.9290 - val_loss: 0.3507 - val_accuracy: 0.8797\n",
      "Epoch 12/1000\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.9320 - val_loss: 0.3398 - val_accuracy: 0.8862\n",
      "Epoch 13/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.1731 - accuracy: 0.9359 - val_loss: 0.3735 - val_accuracy: 0.8816\n",
      "Epoch 14/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.1632 - accuracy: 0.9402 - val_loss: 0.3689 - val_accuracy: 0.8794\n",
      "Epoch 15/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.1556 - accuracy: 0.9420 - val_loss: 0.3744 - val_accuracy: 0.8830\n",
      "Epoch 16/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.1507 - accuracy: 0.9430 - val_loss: 0.3904 - val_accuracy: 0.8786\n",
      "Epoch 17/1000\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1432 - accuracy: 0.9463 - val_loss: 0.3865 - val_accuracy: 0.8834\n",
      "Epoch 18/1000\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1347 - accuracy: 0.9492 - val_loss: 0.4071 - val_accuracy: 0.8791\n",
      "Epoch 19/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.1320 - accuracy: 0.9508 - val_loss: 0.3990 - val_accuracy: 0.8803\n",
      "Epoch 20/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.1276 - accuracy: 0.9527 - val_loss: 0.4037 - val_accuracy: 0.8824\n",
      "Epoch 21/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.1196 - accuracy: 0.9554 - val_loss: 0.4241 - val_accuracy: 0.8808\n",
      "Epoch 22/1000\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1177 - accuracy: 0.9562 - val_loss: 0.4157 - val_accuracy: 0.8840\n",
      "Epoch 23/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.1103 - accuracy: 0.9588 - val_loss: 0.4335 - val_accuracy: 0.8778\n",
      "Epoch 24/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.1069 - accuracy: 0.9603 - val_loss: 0.4329 - val_accuracy: 0.8766\n",
      "Epoch 25/1000\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.1046 - accuracy: 0.9608 - val_loss: 0.4290 - val_accuracy: 0.8831\n",
      "Epoch 26/1000\n",
      "328/328 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9639 - val_loss: 0.4396 - val_accuracy: 0.8810\n",
      "Epoch 27/1000\n",
      "328/328 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9648 - val_loss: 0.4399 - val_accuracy: 0.8790\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/nix-shell.WhEkng/tmpmj6itgjw/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/nix-shell.WhEkng/tmpmj6itgjw/model/data/model/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    epochs=1000,\n",
    "    validation_data=val_set,\n",
    "    callbacks=[EarlyStopping(patience=20, restore_best_weights=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "3614efce-f6b0-45a9-95a3-bfa84823a3cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T11:39:04.977156Z",
     "iopub.status.busy": "2024-02-17T11:39:04.976749Z",
     "iopub.status.idle": "2024-02-17T11:39:05.019027Z",
     "shell.execute_reply": "2024-02-17T11:39:05.018533Z",
     "shell.execute_reply.started": "2024-02-17T11:39:04.977138Z"
    }
   },
   "outputs": [],
   "source": [
    "final_model = keras.Sequential([norm, model])\n",
    "final_model.compile(\n",
    "    optimizer=model.optimizer, loss=model.loss, metrics=model.metrics[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0e924ede-f7ce-4b08-8827-e4766debf8b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T11:39:05.020763Z",
     "iopub.status.busy": "2024-02-17T11:39:05.020555Z",
     "iopub.status.idle": "2024-02-17T11:39:05.293056Z",
     "shell.execute_reply": "2024-02-17T11:39:05.292528Z",
     "shell.execute_reply.started": "2024-02-17T11:39:05.020741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 0s 871us/step - loss: 0.3336 - accuracy: 0.8842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 17:24:05.280093: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14677975496398457193\n",
      "2024-02-17 17:24:05.280123: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6394035354870006688\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = final_model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5adf8-9865-46b2-afea-19a0651b20cc",
   "metadata": {},
   "source": [
    "## 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41904268-0c85-4bd5-95f7-aadd7011c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tarfile\n",
    "# from io import BytesIO\n",
    "\n",
    "# import requests\n",
    "\n",
    "# if not IMDB_DIR.is_dir():\n",
    "#     IMDB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# with BytesIO(\n",
    "#     initial_bytes=requests.get(\n",
    "#         \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "#         allow_redirects=True,\n",
    "#     ).content\n",
    "# ) as archive:\n",
    "#     tar = tarfile.open(fileobj=archive, mode=\"r:gz\")\n",
    "#     tar.extractall(IMDB_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352aa0a-9d88-4a8e-be45-ca3b22e0df8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-17T12:12:18.096881Z",
     "iopub.status.busy": "2024-02-17T12:12:18.096508Z",
     "iopub.status.idle": "2024-02-17T12:12:24.213872Z",
     "shell.execute_reply": "2024-02-17T12:12:24.213445Z",
     "shell.execute_reply.started": "2024-02-17T12:12:18.096846Z"
    }
   },
   "source": [
    "### For Val & Test Sets\n",
    "\n",
    "- 7,500 from both `pos` and `neg` for **Val**\n",
    "- 5,000 from both `pos` and `neg` for **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82ca7d3-7873-46a7-92c0-54816cbc46e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T11:09:27.431201Z",
     "iopub.status.busy": "2024-02-19T11:09:27.430854Z",
     "iopub.status.idle": "2024-02-19T11:09:27.936982Z",
     "shell.execute_reply": "2024-02-19T11:09:27.936631Z",
     "shell.execute_reply.started": "2024-02-19T11:09:27.431187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2278"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "\n",
    "SHUF_BUF_SIZE = 25_000\n",
    "CYCLE_LENGTH = 1000\n",
    "N_THREADS = 8\n",
    "SEED = 42\n",
    "VAL_SIZE = 7500\n",
    "\n",
    "TRAIN_DIR = IMDB_DIR / \"aclImdb\" / \"train\"\n",
    "TEST_DIR = IMDB_DIR / \"aclImdb\" / \"test\"\n",
    "\n",
    "\n",
    "def create_imdb_dataset(\n",
    "    pos_paths: list[str],\n",
    "    neg_paths: list[str],\n",
    "    cycle_len: int = CYCLE_LENGTH,\n",
    "    n_threads: int = N_THREADS,\n",
    "    shuf_buf_size: int | None = None,\n",
    "    batch_size: int = 64,\n",
    ") -> data.Dataset:\n",
    "    dataset = (\n",
    "        data.Dataset.list_files(pos_paths)\n",
    "        .interleave(\n",
    "            lambda filename: data.TextLineDataset(\n",
    "                filename, num_parallel_reads=n_threads\n",
    "            ).map(\n",
    "                lambda line: (line, tf.constant(1, dtype=tf.uint8)),\n",
    "                num_parallel_calls=n_threads,\n",
    "            ),\n",
    "            cycle_length=CYCLE_LENGTH,\n",
    "            num_parallel_calls=n_threads,\n",
    "        )\n",
    "        .concatenate(\n",
    "            data.Dataset.list_files(neg_paths).interleave(\n",
    "                lambda filename: data.TextLineDataset(\n",
    "                    filename, num_parallel_reads=n_threads\n",
    "                ).map(\n",
    "                    lambda line: (line, tf.constant(0, dtype=tf.uint8)),\n",
    "                    num_parallel_calls=n_threads,\n",
    "                ),\n",
    "                cycle_length=cycle_len,\n",
    "                num_parallel_calls=n_threads,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        (\n",
    "            dataset.shuffle(buffer_size=shuf_buf_size, reshuffle_each_iteration=True)\n",
    "            if shuf_buf_size is not None\n",
    "            else dataset\n",
    "        )\n",
    "        .batch(batch_size, num_parallel_calls=n_threads)\n",
    "        .prefetch(data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "\n",
    "val_test_pos_paths, val_test_neg_paths = (\n",
    "    np.fromiter(glob(str(TEST_DIR / \"pos\" / \"*.txt\")), dtype=\"object\"),\n",
    "    np.fromiter(glob(str(TEST_DIR / \"neg\" / \"*.txt\")), dtype=\"object\"),\n",
    ")\n",
    "\n",
    "shuf_idx = np.random.default_rng().permutation(len(val_test_pos_paths))\n",
    "val_pos_paths, val_neg_paths = (\n",
    "    val_test_pos_paths[shuf_idx[:VAL_SIZE]],\n",
    "    val_test_neg_paths[shuf_idx[:VAL_SIZE]],\n",
    ")\n",
    "test_pos_paths, test_neg_paths = (\n",
    "    val_test_pos_paths[shuf_idx[VAL_SIZE:]],\n",
    "    val_test_neg_paths[shuf_idx[VAL_SIZE:]],\n",
    ")\n",
    "\n",
    "del val_test_pos_paths, val_test_neg_paths\n",
    "\n",
    "train_set = create_imdb_dataset(\n",
    "    pos_paths=glob(str(TRAIN_DIR / \"pos\" / \"*.txt\")),\n",
    "    neg_paths=glob(str(TRAIN_DIR / \"neg\" / \"*.txt\")),\n",
    "    shuf_buf_size=SHUF_BUF_SIZE,\n",
    ")\n",
    "val_set = create_imdb_dataset(pos_paths=val_pos_paths, neg_paths=val_neg_paths)\n",
    "test_set = create_imdb_dataset(pos_paths=test_pos_paths, neg_paths=test_neg_paths)\n",
    "\n",
    "del val_pos_paths, val_neg_paths, test_pos_paths, test_neg_paths\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "227b835d-5d56-46fa-bcf0-42497ad7fe71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T11:09:28.575727Z",
     "iopub.status.busy": "2024-02-19T11:09:28.575558Z",
     "iopub.status.idle": "2024-02-19T11:09:36.985313Z",
     "shell.execute_reply": "2024-02-19T11:09:36.984859Z",
     "shell.execute_reply.started": "2024-02-19T11:09:28.575714Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 16:54:36.525954: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16703509877230826048\n",
      "2024-02-19 16:54:36.526086: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 7508873984737559684\n",
      "2024-02-19 16:54:36.526142: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 15874770449440171858\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "text_vec = layers.TextVectorization()\n",
    "text_vec.adapt(train_set.take(5000).map(lambda X, y: X, num_parallel_calls=N_THREADS))\n",
    "\n",
    "train_set = train_set.map(lambda X, y: (text_vec(X), y), num_parallel_calls=N_THREADS)\n",
    "val_set = val_set.map(lambda X, y: (text_vec(X), y), num_parallel_calls=N_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd201a4-3d67-458f-bee8-dc3fbc538d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T11:09:37.649411Z",
     "iopub.status.busy": "2024-02-19T11:09:37.648451Z",
     "iopub.status.idle": "2024-02-19T11:09:37.748844Z",
     "shell.execute_reply": "2024-02-19T11:09:37.748036Z",
     "shell.execute_reply.started": "2024-02-19T11:09:37.649331Z"
    }
   },
   "outputs": [],
   "source": [
    "DROPOUT_RATE = 0.5\n",
    "EMBED_OUT = 50\n",
    "\n",
    "\n",
    "def compute_sentence_embeddings(word_embeds: tf.Tensor, sum_axis: int = 1) -> tf.Tensor:\n",
    "    n_words = tf.math.count_nonzero(\n",
    "        tf.math.count_nonzero(word_embeds, axis=-1), axis=-1, keepdims=True\n",
    "    )\n",
    "\n",
    "    return tf.reduce_sum(word_embeds, axis=sum_axis) / tf.sqrt(\n",
    "        tf.cast(n_words, dtype=word_embeds.dtype)\n",
    "    )\n",
    "\n",
    "\n",
    "sentiment_model = keras.models.Sequential(\n",
    "    [\n",
    "        layers.Embedding(input_dim=text_vec.vocabulary_size(), output_dim=EMBED_OUT),\n",
    "        layers.Lambda(compute_sentence_embeddings),\n",
    "        layers.Dense(100, activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(rate=DROPOUT_RATE),\n",
    "        layers.Dense(50, activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(rate=DROPOUT_RATE),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "sentiment_model.compile(\n",
    "    optimizer=\"nadam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", \"Precision\", \"Recall\"],\n",
    "    jit_compile=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f60576-8ebc-4eea-93f2-785d8074a4e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T10:55:25.431958Z",
     "iopub.status.busy": "2024-02-19T10:55:25.431842Z",
     "iopub.status.idle": "2024-02-19T10:55:25.445346Z",
     "shell.execute_reply": "2024-02-19T10:55:25.445026Z",
     "shell.execute_reply.started": "2024-02-19T10:55:25.431946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.535534 , 4.9497476, 2.1213205],\n",
       "       [6.       , 0.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_example = tf.constant(\n",
    "    [\n",
    "        [[1.0, 2.0, 3.0], [4.0, 5.0, 0.0], [0.0, 0.0, 0.0]],\n",
    "        [[6.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]],\n",
    "    ]\n",
    ")\n",
    "\n",
    "compute_sentence_embeddings(another_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd3f471f-d2a8-4a75-a8f3-d08279dbccff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T11:09:41.704306Z",
     "iopub.status.busy": "2024-02-19T11:09:41.703420Z",
     "iopub.status.idle": "2024-02-19T11:15:06.402832Z",
     "shell.execute_reply": "2024-02-19T11:15:06.401876Z",
     "shell.execute_reply.started": "2024-02-19T11:09:41.704265Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/19 16:54:41 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n",
      "2024/02/19 16:54:41 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '1b6c93b23e0d432880724c82215decbd', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 16:54:46.432064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-02-19 16:54:46.496735: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffd6dbfbfb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-19 16:54:46.496764: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti, Compute Capability 8.9\n",
      "2024-02-19 16:54:46.502730: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-19 16:54:46.509799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "2024-02-19 16:54:46.657751: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    391/Unknown - 68s 159ms/step - loss: 0.5072 - accuracy: 0.7577 - precision: 0.7569 - recall: 0.7593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 16:55:49.560964: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 15307283253652429124\n",
      "2024-02-19 16:55:49.560991: I tensorflow/core/framework/local_rendezvous.cc:409] Local rendezvous send item cancelled. Key hash: 15384726380896506838\n",
      "2024-02-19 16:55:49.561000: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 2394626338979982826\n",
      "2024-02-19 16:55:49.561012: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 1692950827254816456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 70s 166ms/step - loss: 0.5072 - accuracy: 0.7577 - precision: 0.7569 - recall: 0.7593 - val_loss: 0.3872 - val_accuracy: 0.8625 - val_precision: 0.9106 - val_recall: 0.8040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 16:55:52.138965: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 5456875936774510658\n",
      "2024-02-19 16:55:52.139052: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 10505180421857578688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "391/391 [==============================] - 50s 114ms/step - loss: 0.2127 - accuracy: 0.9216 - precision: 0.9206 - recall: 0.9229 - val_loss: 0.8982 - val_accuracy: 0.6782 - val_precision: 0.9451 - val_recall: 0.3784\n",
      "Epoch 3/20\n",
      "391/391 [==============================] - 38s 87ms/step - loss: 0.1252 - accuracy: 0.9561 - precision: 0.9543 - recall: 0.9581 - val_loss: 0.5998 - val_accuracy: 0.8046 - val_precision: 0.7399 - val_recall: 0.9393\n",
      "Epoch 4/20\n",
      "391/391 [==============================] - 34s 77ms/step - loss: 0.0865 - accuracy: 0.9700 - precision: 0.9698 - recall: 0.9703 - val_loss: 0.5377 - val_accuracy: 0.8209 - val_precision: 0.9173 - val_recall: 0.7053\n",
      "Epoch 5/20\n",
      "391/391 [==============================] - 25s 52ms/step - loss: 0.0643 - accuracy: 0.9776 - precision: 0.9767 - recall: 0.9786 - val_loss: 1.3562 - val_accuracy: 0.7047 - val_precision: 0.9378 - val_recall: 0.4385\n",
      "Epoch 6/20\n",
      "391/391 [==============================] - 22s 46ms/step - loss: 0.0566 - accuracy: 0.9795 - precision: 0.9793 - recall: 0.9797 - val_loss: 0.7070 - val_accuracy: 0.7987 - val_precision: 0.7372 - val_recall: 0.9283\n",
      "Epoch 7/20\n",
      "391/391 [==============================] - 20s 40ms/step - loss: 0.0494 - accuracy: 0.9824 - precision: 0.9829 - recall: 0.9819 - val_loss: 0.4950 - val_accuracy: 0.8411 - val_precision: 0.8382 - val_recall: 0.8455\n",
      "Epoch 8/20\n",
      "391/391 [==============================] - 17s 33ms/step - loss: 0.0410 - accuracy: 0.9864 - precision: 0.9869 - recall: 0.9859 - val_loss: 1.5859 - val_accuracy: 0.6936 - val_precision: 0.9560 - val_recall: 0.4059\n",
      "Epoch 9/20\n",
      "391/391 [==============================] - 17s 31ms/step - loss: 0.0388 - accuracy: 0.9874 - precision: 0.9869 - recall: 0.9878 - val_loss: 0.5910 - val_accuracy: 0.8453 - val_precision: 0.8621 - val_recall: 0.8221\n",
      "Epoch 10/20\n",
      "391/391 [==============================] - 15s 26ms/step - loss: 0.0364 - accuracy: 0.9876 - precision: 0.9881 - recall: 0.9870 - val_loss: 0.9974 - val_accuracy: 0.8183 - val_precision: 0.7559 - val_recall: 0.9401\n",
      "Epoch 11/20\n",
      "391/391 [==============================] - 16s 28ms/step - loss: 0.0315 - accuracy: 0.9894 - precision: 0.9893 - recall: 0.9894 - val_loss: 0.7450 - val_accuracy: 0.8401 - val_precision: 0.8760 - val_recall: 0.7924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/19 17:00:06 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: 'EarlyStopping' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "history = sentiment_model.fit(\n",
    "    train_set,\n",
    "    epochs=20,\n",
    "    validation_data=val_set,\n",
    "    callbacks=EarlyStopping(patience=10, restore_best_weights=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d64e66-40d1-4470-8424-900764c38e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T11:15:06.403659Z",
     "iopub.status.busy": "2024-02-19T11:15:06.403535Z",
     "iopub.status.idle": "2024-02-19T11:15:06.563977Z",
     "shell.execute_reply": "2024-02-19T11:15:06.563166Z",
     "shell.execute_reply.started": "2024-02-19T11:15:06.403646Z"
    }
   },
   "outputs": [],
   "source": [
    "final_sentiment_model = keras.models.Sequential(\n",
    "    [layers.Input(shape=(), dtype=tf.string), text_vec, sentiment_model]\n",
    ")\n",
    "final_sentiment_model.compile(\n",
    "    optimizer=sentiment_model.optimizer,\n",
    "    loss=sentiment_model.loss,\n",
    "    metrics=sentiment_model.metrics[1:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1be050de-13dd-4129-af09-c2390201915d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T11:15:06.564518Z",
     "iopub.status.busy": "2024-02-19T11:15:06.564399Z",
     "iopub.status.idle": "2024-02-19T11:15:08.951118Z",
     "shell.execute_reply": "2024-02-19T11:15:08.950687Z",
     "shell.execute_reply.started": "2024-02-19T11:15:06.564506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 11ms/step - loss: 0.3835 - accuracy: 0.8499 - precision: 0.8931 - recall: 0.7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:00:08.804686: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 15665579406873082381\n",
      "2024-02-19 17:00:08.804716: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 14268400143922188807\n",
      "2024-02-19 17:00:08.804726: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 16955261489581513509\n",
      "2024-02-19 17:00:08.804733: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 3626514809993161463\n",
      "2024-02-19 17:00:08.804741: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 1298354914411440750\n"
     ]
    }
   ],
   "source": [
    "test_metrics = final_sentiment_model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5aeb1-02af-484a-bf35-065bc01c0440",
   "metadata": {},
   "source": [
    "### Using TFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35118b2e-0d5a-48b1-92da-a9874acfcc74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T11:23:37.482111Z",
     "iopub.status.busy": "2024-02-19T11:23:37.481691Z",
     "iopub.status.idle": "2024-02-19T11:23:37.570620Z",
     "shell.execute_reply": "2024-02-19T11:23:37.570094Z",
     "shell.execute_reply.started": "2024-02-19T11:23:37.482074Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "train, val, test = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=[\"train\", \"test[:75%]\", \"test[75%:]\"],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "256cf9fd-7614-4717-8c95-2265fe133126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T11:24:39.698790Z",
     "iopub.status.busy": "2024-02-19T11:24:39.698614Z",
     "iopub.status.idle": "2024-02-19T11:24:39.819169Z",
     "shell.execute_reply": "2024-02-19T11:24:39.818860Z",
     "shell.execute_reply.started": "2024-02-19T11:24:39.698777Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n",
      "\n",
      "tf.Tensor(b\"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\", shape=(), dtype=string) tf.Tensor(1, shape=(), dtype=int64)\n",
      "\n",
      "tf.Tensor(b\"In a nutshell, skip this movie, it's that bad. In short, this movie is about a weapons factory where secret weapons are being developed. Because they make bad things, they aren't popular so to speak. A new female CEO comes in to clear things up, and make sure the reputation of the company will be improved. She does this by leaking company confidential information to the press... Do you believe this? Furthermore she starts to fire people she has never seen. Incredible uh? A pacifistic group tries to destroy the company's mainframe, because there are the blueprint located of those secret weapons. This mainframe is located in the bottom of the building hidden in a kind of vault. Of course the movie would not be complete without the mad scientist and a robot which is the ultimate killer machine, which resembles like an 'Alien' from the Alien movies. The mad scientist likes the female CEO.<br /><br />The mad scientist instructs the robot to kill everyone, and so protects his job, rise in chain of command, and make the movie interesting. The pacifists team up with the CEO and another person of the board of directors to escape from the robot. Further down the line they agree to blow up this evil computer mainframe, whilst avoiding the robot. They also discover that the factory was developing a part man, part machine soldier. They can erase a persons memory and replace it by a veteran soldier's one. One of the pacifists is transformed in such a soldier and will hunt the killer robot. I guess the mad scientist also wrote the script of this movie. This super soldier looks and acts much the same as Robocop, though not as funny.<br /><br />It boils down to this. People are running, being chased by a killer robot, are hurt by it, but they do not seem to troubled by that, besides limping a bit, and of course the female CEO is the leading character of this movie, and cannot be killed, i.e. survives every attack, explosion, you name it. I won't bother you by the chase, let's skip to the end. They have lots of weapons, yes the pacifist too and they know how to use them. When they're at the roof of the building they empty all there weapons upon the killer robot. They step into an elevator which is used to clean outside windows. And then the female CEO knows some magic as well, at the roof she was complaining about being out of bullets, and like magic the gun is reloaded. This way she can shoot the cables and let the elevator plummet 70 stories or so, and let it stop right above ground surface by pulling the brake. And to top it all off, the police is waiting there for them. The robot jumps after them, and kills the cops. Hilarious no? The robot chases them down the vault where the mainframe is, and when finally the robot is so close to her, that he can touch/kill her, it stops. Because the mad scientist did not want her to be killed. A better name for this guy would be the idiot scientist. Although he is the one who made this movie watchable. At this moment I was already pulling for the killer robot to finish them all of, so the movie would end.<br /><br />I cannot believe that this movie rates this high, and this is why I wrote this comment. Avoid this movie like the plague. It's a monster, and I'm not talking about the Death Machine.\", shape=(), dtype=string) tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:09:39.783428: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-02-19 17:09:39.816266: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for X, y in train.take(1):\n",
    "    print(X, y)\n",
    "\n",
    "print()\n",
    "\n",
    "for X, y in val.take(1):\n",
    "    print(X, y)\n",
    "\n",
    "print()\n",
    "\n",
    "for X, y in test.take(1):\n",
    "    print(X, y)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
