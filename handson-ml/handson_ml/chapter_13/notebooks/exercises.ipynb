{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "df4aa2e9-8b82-4f54-8555-c46365db88ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T17:04:33.901660Z",
     "iopub.status.busy": "2024-02-14T17:04:33.900376Z",
     "iopub.status.idle": "2024-02-14T17:04:33.912372Z",
     "shell.execute_reply": "2024-02-14T17:04:33.911325Z",
     "shell.execute_reply.started": "2024-02-14T17:04:33.901587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/twogoodap/Coding_Playground/Machine_Learning/Hands_on_Machine_Learning/handson-ml/mlruns\n",
      "/home/twogoodap/Coding_Playground/Machine_Learning/Hands_on_Machine_Learning/handson-ml/handson_ml/chapter_13/dataset\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import data, keras\n",
    "\n",
    "ROOT_DIR = Path().absolute().parent\n",
    "MLRUNS_DIR = ROOT_DIR.parents[1] / \"mlruns\"\n",
    "DATA_DIR = ROOT_DIR / \"dataset\"\n",
    "TFR_DIR = DATA_DIR / \"tfrecords\"\n",
    "PROTO_DIR = ROOT_DIR / \"protobufs\"\n",
    "\n",
    "if not TFR_DIR.is_dir():\n",
    "    TFR_DIR.mkdir(parents=True)\n",
    "if not PROTO_DIR.is_dir():\n",
    "    PROTO_DIR.mkdir(parents=True)\n",
    "\n",
    "print(f\"{MLRUNS_DIR}\\n{DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96619b4-58cf-48c3-8f89-9360039455c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T10:44:47.870898Z",
     "iopub.status.busy": "2024-02-14T10:44:47.869869Z",
     "iopub.status.idle": "2024-02-14T10:44:48.490176Z",
     "shell.execute_reply": "2024-02-14T10:44:48.489249Z",
     "shell.execute_reply.started": "2024-02-14T10:44:47.870840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/twogoodap/Coding_Playground/Machine_Learning/Hands_on_Machine_Learning/handson-ml/handson_ml/chapter_13/mlruns/2', creation_time=1699089661167, experiment_id='2', last_update_time=1699089661167, lifecycle_stage='active', name='tf_data_api', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(f\"sqlite:///{MLRUNS_DIR}/mlflow.db\")\n",
    "mlflow.set_experiment(\"tf_data_api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c368e5-b864-4a1c-b119-cec8d8de262e",
   "metadata": {},
   "source": [
    "## 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef663e6f-b917-4741-91da-d57074429f25",
   "metadata": {},
   "source": [
    "```proto\n",
    "syntax = \"proto3\";\n",
    "\n",
    "message BytesList { repeated bytes value = 1; }\n",
    "message FloatList { repeated float value = 1 [packed = true]; }\n",
    "message Int64List { repeated int64 value = 1 [packed = true]; }\n",
    "message Feature {\n",
    "    oneof kind {\n",
    "        BytesList bytes_list = 1;\n",
    "        FloatList float_list = 2;\n",
    "        Int64List int64_list = 3;\n",
    "    }\n",
    "};\n",
    "message Features { map<string, Feature> feature = 1; };\n",
    "message Example { Features features = 1; };\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "80e57c12-d1e2-4934-99c2-86f3291daf23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T17:02:57.963361Z",
     "iopub.status.busy": "2024-02-14T17:02:57.963194Z",
     "iopub.status.idle": "2024-02-14T17:02:57.972793Z",
     "shell.execute_reply": "2024-02-14T17:02:57.971980Z",
     "shell.execute_reply.started": "2024-02-14T17:02:57.963348Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.train import BytesList, Example, Feature, Features, Int64List\n",
    "\n",
    "\n",
    "def fashion_mnist_to_tfrecord(\n",
    "    data: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    record_dir: Path = TFR_DIR / \"fashion_mnist\",\n",
    "    n_chunks: int = 10,\n",
    "    seed: int = 42,\n",
    ") -> None:\n",
    "    def __break_dataset_to_chunks(\n",
    "        data: np.ndarray, labels: np.ndarray, n_chunks: int, seed: int\n",
    "    ) -> Generator[tuple[np.ndarray, np.ndarray], None, None]:\n",
    "        shuf_idx = np.random.default_rng(seed=seed).permutation(len(labels))\n",
    "        chunk_size = len(labels) // n_chunks\n",
    "\n",
    "        return (\n",
    "            (\n",
    "                data[(idx := shuf_idx[i * chunk_size : (i + 1) * chunk_size])],\n",
    "                labels[idx],\n",
    "            )\n",
    "            for i in range(n_chunks)\n",
    "        )\n",
    "\n",
    "    def __fashion_mnist_example(image: np.ndarray | tf.Tensor, label: str) -> Example:\n",
    "        return Example(\n",
    "            features=Features(\n",
    "                feature={\n",
    "                    \"image\": Feature(\n",
    "                        bytes_list=BytesList(\n",
    "                            value=[\n",
    "                                tf.io.serialize_tensor(image.astype(\"float32\")).numpy()\n",
    "                            ]\n",
    "                        )\n",
    "                    ),\n",
    "                    \"label\": Feature(int64_list=Int64List(value=[int(label)])),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        data, labels, test_size=0.2, random_state=seed, stratify=target\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, random_state=seed, stratify=y_train_full\n",
    "    )\n",
    "    del X_train_full, y_train_full\n",
    "\n",
    "    splits = {}\n",
    "    for split_name, split_data, split_labels in zip(\n",
    "        (\"train\", \"val\", \"test\"), (X_train, X_val, X_test), (y_train, y_val, y_test)\n",
    "    ):\n",
    "        splits[split_name] = __break_dataset_to_chunks(\n",
    "            split_data, split_labels, n_chunks, seed\n",
    "        )\n",
    "\n",
    "    del X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    gc.collect()\n",
    "\n",
    "    record_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for name, split in splits.items():\n",
    "        (record_dir / name).mkdir(exist_ok=True)\n",
    "\n",
    "        for i, (imgs, lbls) in enumerate(split):\n",
    "            with tf.io.TFRecordWriter(\n",
    "                str(record_dir / name / f\"fashion_mnist_{i:03}.tfrecord\")\n",
    "            ) as rec_file:\n",
    "                for img, lbl in zip(imgs, lbls):\n",
    "                    rec_file.write(\n",
    "                        __fashion_mnist_example(img, lbl).SerializeToString()\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ffe389cb-39cd-4d49-8cdf-2e18614770e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T17:03:53.063655Z",
     "iopub.status.busy": "2024-02-14T17:03:53.062825Z",
     "iopub.status.idle": "2024-02-14T17:04:06.272954Z",
     "shell.execute_reply": "2024-02-14T17:04:06.272141Z",
     "shell.execute_reply.started": "2024-02-14T17:03:53.063597Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images, targets = (\n",
    "    (fmnist := fetch_openml(name=\"Fashion-MNIST\", as_frame=False, parser=\"auto\")).data,\n",
    "    fmnist.target,\n",
    ")\n",
    "\n",
    "fashion_mnist_to_tfrecord(images, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "de5bdce8-5163-4bde-a879-884bb91e1080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T17:06:01.399348Z",
     "iopub.status.busy": "2024-02-14T17:06:01.398971Z",
     "iopub.status.idle": "2024-02-14T17:06:01.522963Z",
     "shell.execute_reply": "2024-02-14T17:06:01.522326Z",
     "shell.execute_reply.started": "2024-02-14T17:06:01.399314Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "from tensorflow.io import FixedLenFeature, VarLenFeature\n",
    "\n",
    "\n",
    "def parse_fashion_mnist_tfrecord(record: bytes) -> tuple[tf.Tensor, tf.Tensor]:\n",
    "    parsed = tf.io.parse_example(\n",
    "        record,\n",
    "        features={\n",
    "            \"image\": VarLenFeature(dtype=tf.string),\n",
    "            \"label\": FixedLenFeature(shape=(), dtype=tf.int64),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        tf.io.parse_tensor(parsed[\"image\"].values[0], out_type=tf.float32),\n",
    "        tf.cast(parsed[\"label\"], dtype=tf.uint8),\n",
    "    )\n",
    "\n",
    "\n",
    "train_set = data.TFRecordDataset(\n",
    "    glob(str(TFR_DIR / \"fashion_mnist\" / \"train\" / \"fashion_mnist_*.tfrecord\")),\n",
    "    num_parallel_reads=data.AUTOTUNE,\n",
    ").map(parse_fashion_mnist_tfrecord)\n",
    "\n",
    "val_set = data.TFRecordDataset(\n",
    "    glob(str(TFR_DIR / \"fashion_mnist\" / \"val\" / \"fashion_mnist_*.tfrecord\")),\n",
    "    num_parallel_reads=data.AUTOTUNE,\n",
    ").map(parse_fashion_mnist_tfrecord)\n",
    "\n",
    "test_set = data.TFRecordDataset(\n",
    "    glob(str(TFR_DIR / \"fashion_mnist\" / \"test\" / \"fashion_mnist_*.tfrecord\")),\n",
    "    num_parallel_reads=data.AUTOTUNE,\n",
    ").map(parse_fashion_mnist_tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7b7c6ce1-b454-43fd-8a40-42bff4bcbe39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T17:07:59.877348Z",
     "iopub.status.busy": "2024-02-14T17:07:59.876603Z",
     "iopub.status.idle": "2024-02-14T17:07:59.966131Z",
     "shell.execute_reply": "2024-02-14T17:07:59.965738Z",
     "shell.execute_reply.started": "2024-02-14T17:07:59.877295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "(<tf.Tensor: shape=(32, 784), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(32,), dtype=uint8, numpy=\n",
      "array([7, 8, 5, 0, 4, 8, 9, 0, 7, 2, 7, 4, 2, 8, 7, 1, 5, 4, 9, 2, 8, 6,\n",
      "       3, 5, 8, 2, 9, 8, 0, 8, 3, 9], dtype=uint8)>)\n",
      "\n",
      "Val:\n",
      "(<tf.Tensor: shape=(32, 784), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(32,), dtype=uint8, numpy=\n",
      "array([3, 8, 1, 3, 5, 4, 4, 9, 1, 6, 4, 3, 6, 7, 9, 6, 1, 2, 7, 6, 8, 8,\n",
      "       8, 1, 5, 9, 5, 7, 8, 2, 6, 3], dtype=uint8)>)\n",
      "\n",
      "Test:\n",
      "(<tf.Tensor: shape=(32, 784), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(32,), dtype=uint8, numpy=\n",
      "array([3, 8, 0, 5, 6, 3, 1, 5, 0, 4, 3, 1, 5, 5, 3, 3, 2, 2, 5, 6, 8, 1,\n",
      "       5, 4, 5, 5, 7, 3, 0, 5, 4, 8], dtype=uint8)>)\n"
     ]
    }
   ],
   "source": [
    "for trs in train_set.batch(32).take(1):\n",
    "    print(\"Train:\")\n",
    "    print(trs)\n",
    "\n",
    "for vs in val_set.batch(32).take(1):\n",
    "    print(\"\\nVal:\")\n",
    "    print(vs)\n",
    "\n",
    "for tes in test_set.batch(32).take(1):\n",
    "    print(\"\\nTest:\")\n",
    "    print(tes)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
